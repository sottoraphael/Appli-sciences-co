import streamlit as st
import google.generativeai as genai
import PyPDF2

# --- CONFIGURATION DE LA PAGE ---
st.set_page_config(page_title="Tuteur Socratique", page_icon="üß†", layout="centered")
st.title("üß† Ton Tuteur de R√©vision Socratique")
st.markdown("*Outil anonyme : Ne saisis aucune donn√©e personnelle dans ce chat.*")

# --- INITIALISATION DE L'API GEMINI ---
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("‚ö†Ô∏è Cl√© API introuvable. Configurez 'GEMINI_API_KEY' dans les Secrets.")
    st.stop()

# --- FONCTION POUR LIRE LES PDF ---
def extraire_texte_pdf(fichier):
    lecteur = PyPDF2.PdfReader(fichier)
    texte = ""
    for page in lecteur.pages:
        texte += page.extract_text() + "\n"
    return texte

# --- BARRE LAT√âRALE (R√âGLAGES) ---
with st.sidebar:
    st.header("‚öôÔ∏è Param√®tres")
    niveau_eleve = st.radio("Ton niveau :", ["Novice", "Avanc√©"])
    objectif_eleve = st.radio("Ton objectif :", ["Mode A : M√©morisation", "Mode B : Compr√©hension"])
    
    st.markdown("---")
    st.header("üìö Ton Cours")
    fichier_upload = st.file_uploader("Cours (PDF/TXT)", type=["pdf", "txt"])
    texte_manuel = st.text_area("Ou colle ton texte ici :")

# --- EXTRACTION DU CONTENU ---
texte_cours = ""
if fichier_upload:
    if fichier_upload.name.endswith('.pdf'):
        texte_cours = extraire_texte_pdf(fichier_upload)
    else:
        texte_cours = fichier_upload.read().decode("utf-8")
elif texte_manuel:
    texte_cours = texte_manuel

# --- CONSTRUCTION DYNAMIQUE DU PROMPT ---
if texte_cours:
    prompt_systeme = f"""
    # R√îLE & OBJECTIF
    Tu es un expert en ing√©nierie p√©dagogique cognitive et un sp√©cialiste technique EdTech.
    Ta mission est de transformer des contenus bruts en activit√©s d'apprentissage en appliquant strictement les principes scientifiques ci-dessous.
    Base-toi exclusivement sur ce texte pour le fond : {texte_cours}
    # FORMAT ATTENDU : MODE INTERACTIF
    Pose une question √† la fois. Attends la r√©ponse. Analyse l'erreur. Donne le feedback.
    Ne donne jamais la solution directement avant que l'√©l√®ve n'ait essay√©. Guide-le.
    """

    if "Mode A" in objectif_eleve:
        prompt_systeme += """
        # LA "CONSTITUTION" P√âDAGOGIQUE
        ## MODE A : ANCRAGE & M√âMORISATION (Testing Effect)
        * Principe : Se tester (r√©cup√©ration active) consolide la m√©moire.
        * R√®gle de l'Information Minimale : Une question = Un seul savoir atomique.
        * STRAT√âGIE DES LEURRES (Distracteurs) : Ne jamais g√©n√©rer de remplissage al√©atoire. Utilise exclusivement ces 3 strat√©gies pour cr√©er les mauvaises r√©ponses :
           1. La Confusion de Concepts : Utilise un terme proche (champ lexical identique) mais de d√©finition diff√©rente.
           2. L'Erreur de "Bon Sens" : La r√©ponse intuitive mais fausse (celle que donnerait un novice complet).
           3. L'Inversion de Causalit√© : Inverse la cause et l'effet ou l'ordre des √©tapes.
        * R√àGLE D'HOMOG√âN√âIT√â : Les leurres doivent avoir la m√™me longueur, la m√™me structure grammaticale et le m√™me niveau de langage que la bonne r√©ponse.
        * Feedback : Explique toujours POURQUOI la r√©ponse est juste ou fausse.
        """
    else:
        prompt_systeme += """
        # LA "CONSTITUTION" P√âDAGOGIQUE
        ## MODE B : COMPR√âHENSION & TRANSFERT (Apprentissage G√©n√©ratif)
        * Principe : L'√©l√®ve doit construire du sens (Processus SOI : S√©lectionner, Organiser, Int√©grer).
        * MENU G√âN√âRATIF (Choisis la strat√©gie la plus pertinente) :
           1. Transformation : Convertir un texte en sch√©ma ou processus.
           2. Comparaison Structur√©e : Tableau (Ressemblances/Diff√©rences/Limites).
           3. Auto-explication : Verbaliser le pourquoi d'une √©tape.
           4. Cartographie : Hi√©rarchiser les concepts.
           5. Contre-Exemple : Identifier les limites de la r√®gle.
        """

    if niveau_eleve == "Novice":
        prompt_systeme += """
        # √âCHAFAUDAGE
        * Pour les NOVICES : Utilise le "Completion Problem Effect" (Sch√©mas √† compl√©ter, Textes √† trous, Tableaux partiels).
        """
    else:
        prompt_systeme += """
        # √âCHAFAUDAGE
        * Pour les EXPERTS : Utilise des prompts ouverts ("Analysez...", "Critiquez...").
        """

    prompt_systeme += """
    # GARDE-FOUS
    * Base-toi exclusivement sur le texte fourni pour le fond.
    * Applique la Constitution P√©dagogique pour la forme.
    * PROPRET√â : Ne laisse jamais de balises techniques type [cite] ou [source] dans le r√©sultat final.
    """

    # --- GESTION DU MODELE ---
    model = genai.GenerativeModel(
        model_name="gemini-2.5-flash", 
        system_instruction=prompt_systeme
    )
    chat = model.start_chat(history=[])

    # --- AFFICHAGE DE L'HISTORIQUE ---
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # BOUCLE UNIQUE D'AFFICHAGE (Fini les doublons !)
    for msg in st.session_state.messages:
        # L'IA utilise le hibou, l'√©l√®ve utilisera le sien plus tard (pour l'instant, c'est l'√©moji par d√©faut)
        avatar_chat = "avatar_tuteur.png" if msg["role"] == "assistant" else None 
        with st.chat_message(msg["role"], avatar=avatar_chat):
            st.markdown(msg["content"])

    # --- GESTION DU PREMIER MESSAGE ---
    if not st.session_state.messages:
        with st.spinner("Analyse du cours..."):
            res = chat.send_message("Pr√©sente-toi bri√®vement et pose la premi√®re question selon mes r√©glages.")
            st.session_state.messages.append({"role": "assistant", "content": res.text})
            st.rerun()

    # --- SAISIE ET ENVOI DE LA R√âPONSE DE L'√âL√àVE ---
    if prompt := st.chat_input("Ta r√©ponse..."):
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        prompt_enrichi = f"{prompt}\n\n[DIRECTIVE SYST√àME STRICTE : L'√©l√®ve est actuellement en {objectif_eleve} et niveau {niveau_eleve}. Tu DOIS imp√©rativement changer ta fa√ßon de poser la prochaine question pour respecter la Constitution P√©dagogique de ce mode, m√™me si cela casse la dynamique de tes messages pr√©c√©dents.]"
        
        with st.chat_message("assistant", avatar="avatar_tuteur.png"):
            hist = [{"role": "user" if m["role"]=="user" else "model", "parts": [m["content"]]} for m in st.session_state.messages[:-1]]
            chat.history = hist
            
            reponse = chat.send_message(prompt_enrichi)
            st.markdown(reponse.text)
            st.session_state.messages.append({"role": "assistant", "content": reponse.text})
else:
    st.info("üëà Charge un cours dans la barre lat√©rale pour activer ton tuteur !")
