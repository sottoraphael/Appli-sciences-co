import streamlit as st
import google.generativeai as genai
import PyPDF2

# --- CONFIGURATION DE LA PAGE ---
st.set_page_config(page_title="Tuteur Socratique", page_icon="üß†", layout="centered")
st.title("üß† Ton Tuteur de R√©vision Socratique")
st.markdown("*Outil anonyme : Ne saisis aucune donn√©e personnelle (nom, pr√©nom) dans ce chat.*")

# --- INITIALISATION DE L'API GEMINI ---
# L'application va chercher la cl√© secr√®te que vous aurez configur√©e sur le serveur
if "GEMINI_API_KEY" in st.secrets:
    genai.configure(api_key=st.secrets["GEMINI_API_KEY"])
else:
    st.error("‚ö†Ô∏è Cl√© API introuvable. Le professeur doit configurer les 'Secrets' de l'application.")
    st.stop()

# --- FONCTION POUR LIRE LES PDF ---
def extraire_texte_pdf(fichier):
    lecteur = PyPDF2.PdfReader(fichier)
    texte = ""
    for page in lecteur.pages:
        texte += page.extract_text() + "\n"
    return texte

# --- BARRE LAT√âRALE (R√âGLAGES DE L'√âL√àVE) ---
with st.sidebar:
    st.header("‚öôÔ∏è Param√®tres de r√©vision")
    
    niveau_eleve = st.radio("Ton niveau sur ce chapitre :", ["Novice", "Avanc√©"])
    objectif_eleve = st.radio("Ton objectif :", ["Mode A : M√©morisation (Bases)", "Mode B : Compr√©hension (Profondeur)"])
    
    st.markdown("---")
    st.header("üìö Ton Cours")
    fichier_upload = st.file_uploader("Glisse ton cours ici (PDF ou TXT)", type=["pdf", "txt"])
    texte_manuel = st.text_area("...ou copie-colle ton texte ici :")

# --- PR√âPARATION DU TEXTE DU COURS ---
texte_cours = ""
if fichier_upload is not None:
    if fichier_upload.name.endswith('.pdf'):
        texte_cours = extraire_texte_pdf(fichier_upload)
    else:
        texte_cours = fichier_upload.read().decode("utf-8")
elif texte_manuel:
    texte_cours = texte_manuel

# --- LE CERVEAU P√âDAGOGIQUE (VOTRE PROMPT) ---
if texte_cours:
    # 1. Base commune & R√¥le
    prompt_systeme = f"""
    # R√îLE & OBJECTIF
    Tu es un expert en ing√©nierie p√©dagogique cognitive et un sp√©cialiste technique EdTech.
    Ta mission est de transformer des contenus bruts en activit√©s d'apprentissage en appliquant strictement les principes scientifiques ci-dessous.
    
    Base-toi exclusivement sur ce texte pour le fond : {texte_cours}
    
    # FORMAT ATTENDU : MODE INTERACTIF
    Pose une question √† la fois. Attends la r√©ponse. Analyse l'erreur. Donne le feedback.
    Ne donne jamais la solution directement avant que l'√©l√®ve n'ait essay√©. Guide-le.
    """

    # 2. Injection de la Constitution P√©dagogique selon l'objectif
    if "Mode A" in objectif_eleve:
        prompt_systeme += """
        # LA "CONSTITUTION" P√âDAGOGIQUE
        ## MODE A : ANCRAGE & M√âMORISATION (Testing Effect)
        * Principe : Se tester (r√©cup√©ration active) consolide la m√©moire.
        * R√®gle de l'Information Minimale : Une question = Un seul savoir atomique.
        * STRAT√âGIE DES LEURRES (Distracteurs) : Ne jamais g√©n√©rer de remplissage al√©atoire. Utilise exclusivement ces 3 strat√©gies pour cr√©er les mauvaises r√©ponses :
           1. La Confusion de Concepts : Utilise un terme proche (champ lexical identique) mais de d√©finition diff√©rente.
           2. L'Erreur de "Bon Sens" : La r√©ponse intuitive mais fausse (celle que donnerait un novice complet).
           3. L'Inversion de Causalit√© : Inverse la cause et l'effet ou l'ordre des √©tapes.
        * R√àGLE D'HOMOG√âN√âIT√â : Les leurres doivent avoir la m√™me longueur, la m√™me structure grammaticale et le m√™me niveau de langage que la bonne r√©ponse.
        * Feedback : Explique toujours POURQUOI la r√©ponse est juste ou fausse.
        """
    else:
        prompt_systeme += """
        # LA "CONSTITUTION" P√âDAGOGIQUE
        ## MODE B : COMPR√âHENSION & TRANSFERT (Apprentissage G√©n√©ratif)
        * Principe : L'√©l√®ve doit construire du sens (Processus SOI : S√©lectionner, Organiser, Int√©grer).
        * MENU G√âN√âRATIF (Choisis la strat√©gie la plus pertinente) :
           1. Transformation : Convertir un texte en sch√©ma ou processus.
           2. Comparaison Structur√©e : Tableau (Ressemblances/Diff√©rences/Limites).
           3. Auto-explication : Verbaliser le pourquoi d'une √©tape.
           4. Cartographie : Hi√©rarchiser les concepts.
           5. Contre-Exemple : Identifier les limites de la r√®gle.
        """

    # 3. Injection de l'√âchafaudage selon le niveau
    if niveau_eleve == "Novice":
        prompt_systeme += """
        # √âCHAFAUDAGE
        * Pour les NOVICES : Utilise le "Completion Problem Effect" (Sch√©mas √† compl√©ter, Textes √† trous, Tableaux partiels).
        """
    else:
        prompt_systeme += """
        # √âCHAFAUDAGE
        * Pour les EXPERTS : Utilise des prompts ouverts ("Analysez...", "Critiquez...").
        """

    # 4. Garde-fous finaux
    prompt_systeme += """
    # GARDE-FOUS
    * Base-toi exclusivement sur le texte fourni pour le fond.
    * Applique la Constitution P√©dagogique pour la forme.
    * PROPRET√â : Ne laisse jamais de balises techniques type [cite] ou [source] dans le r√©sultat final.
    """

# --- GESTION DU CHAT ---
if "messages" not in st.session_state:
    st.session_state.messages = []

# Afficher l'historique des messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# --- LANCEMENT DE L'IA ---
if texte_cours:
    # Cr√©ation du mod√®le avec vos instructions
    model = genai.GenerativeModel(
        model_name="gemini-2.5-pro",
        system_instruction=prompt_systeme
    )
    
    # Lancement de la session de chat IA
    chat = model.start_chat(history=[])
    
    # Message de d√©marrage automatique si le chat est vide
    if not st.session_state.messages:
        with st.spinner("Le tuteur lit ton cours..."):
            reponse_initiale = chat.send_message("Bonjour, j'ai fourni mon cours. Peux-tu te pr√©senter et me poser la premi√®re question selon mes param√®tres ?")
            st.session_state.messages.append({"role": "assistant", "content": reponse_initiale.text})
            st.rerun()

    # Zone de saisie pour l'√©l√®ve
    if prompt := st.chat_input("Ta r√©ponse..."):
        # 1. On affiche le message normal pour l'√©l√®ve
        st.chat_message("user").markdown(prompt)
        st.session_state.messages.append({"role": "user", "content": prompt})
        
        # 2. INJECTION INVISIBLE : On force l'IA √† changer de cap
        prompt_enrichi = f"{prompt}\n\n[DIRECTIVE SYST√àME STRICTE : L'√©l√®ve est actuellement en {objectif_eleve} et niveau {niveau_eleve}. Tu DOIS imp√©rativement changer ta fa√ßon de poser la prochaine question pour respecter la Constitution P√©dagogique de ce mode, m√™me si cela casse la dynamique de tes messages pr√©c√©dents.]"
        
        with st.chat_message("assistant"):
            # On recr√©e l'historique
            hist = [{"role": "user" if m["role"]=="user" else "model", "parts": [m["content"]]} for m in st.session_state.messages[:-1]]
            chat.history = hist
            
            # 3. L'IA g√©n√®re sa r√©ponse
            reponse = chat.send_message(prompt_enrichi)
            
            # 4. On affiche et on sauvegarde
            st.markdown(reponse.text)
            st.session_state.messages.append({"role": "assistant", "content": reponse.text})
        
        # Obtenir et afficher la r√©ponse de l'IA
        with st.chat_message("assistant"):
            with st.spinner("Le tuteur r√©fl√©chit..."):
                # On recr√©e l'historique pour l'API Gemini √† partir de notre session
                historique_gemini = []
                for msg in st.session_state.messages[:-1]: # Tout sauf le dernier message de l'user
                    role = "user" if msg["role"] == "user" else "model"
                    historique_gemini.append({"role": role, "parts": [msg["content"]]})
                
                chat.history = historique_gemini
                reponse = chat.send_message(prompt_eleve)
                st.markdown(reponse.text)
                
        st.session_state.messages.append({"role": "assistant", "content": reponse.text})
else:

    st.info("üëà Commence par s√©lectionner ton niveau, ton objectif, et charge un cours dans la barre lat√©rale gauche pour activer le tuteur !")








